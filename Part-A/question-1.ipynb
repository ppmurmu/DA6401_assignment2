{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2APfY9R7e08-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d4f9000-ad04-4f61-e8f5-6ba57f09cd5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleCNN(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (act1): ReLU()\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (act2): ReLU()\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc): Linear(in_features=2048, out_features=128, bias=True)\n",
            "  (out): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n",
            "Output shape: torch.Size([4, 10])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_channels=3,     # Number of input channels, e.g., 3 for RGB images\n",
        "                 num_classes=10,       # Number of classes in the dataset\n",
        "                 num_filters=32,       # m: Number of filters in each convolutional layer\n",
        "                 kernel_size=3,        # k: Kernel size (kÃ—k)\n",
        "                 dense_neurons=128):   # n: Number of neurons in the dense (fully connected) layer\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        # Convolution Block 1: Convolution -> Activation -> MaxPool\n",
        "        self.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=num_filters, kernel_size=kernel_size, padding=1)\n",
        "        self.act1 = nn.ReLU()  # Activation function (can be replaced with GELU, SiLU, Mish, etc.)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)  # Halves the spatial dimensions\n",
        "\n",
        "        # Convolution Block 2: You may extend the network with more blocks as needed\n",
        "        self.conv2 = nn.Conv2d(in_channels=num_filters, out_channels=num_filters, kernel_size=kernel_size, padding=1)\n",
        "        self.act2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "\n",
        "        # After two pooling operations (with kernel size 2), the spatial size reduces to 8x8.\n",
        "        flattened_size = num_filters * 8 * 8\n",
        "\n",
        "        # Fully Connected (Dense) Layers:\n",
        "        # First dense layer with configurable number of neurons\n",
        "        self.fc = nn.Linear(in_features=flattened_size, out_features=dense_neurons)\n",
        "\n",
        "        # Output layer: number of neurons equal to number of classes\n",
        "        self.out = nn.Linear(in_features=dense_neurons, out_features=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply first conv block\n",
        "        x = self.conv1(x)   # Convolution\n",
        "        x = self.act1(x)    # Activation\n",
        "        x = self.pool1(x)   # Max pooling\n",
        "\n",
        "        # Apply second conv block\n",
        "        x = self.conv2(x)\n",
        "        x = self.act2(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        # Flatten the output feature maps into a vector\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Pass through the fully connected layer then the output layer\n",
        "        x = self.fc(x)\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    # Instantiate the network with example parameters\n",
        "    model = SimpleCNN(input_channels=3, num_classes=10, num_filters=32, kernel_size=3, dense_neurons=128)\n",
        "    print(model)\n",
        "\n",
        "    # Create a sample input tensor (e.g., a batch of 4 RGB images of size 32x32)\n",
        "    sample_input = torch.randn(4, 3, 32, 32)\n",
        "    sample_output = model(sample_input)\n",
        "    print(\"Output shape:\", sample_output.shape)\n"
      ]
    }
  ]
}